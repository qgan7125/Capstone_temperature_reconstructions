---
title: "Least Square Monte Carlo"
author: "Quan Gan"
date: "3/1/2022"
output: 
  html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

library(data.table)
library(tidyverse)
library(Rmisc)
library(knitr)
library(greekLetters)
```

## Load data in
There are three data sets with low, intermediate, and high errors.
```{r}
data_low <- read_csv("../Data/Dataset_S1_Mar8.csv")
data_intermediate <- read_csv("../Data/Dataset_S2_Mar8.csv")
data_high <- read_csv("../Data/Dataset_S3_Mar8.csv")
```
Model least square OLS
$$
D47 = \alpha + \beta * Temperature
$$
Create Monte Carlo function
```{r}
MonteCarlo <- function(seed, n, m, dataInput){
  set.seed(seed)
  # alpha_TRUE <- 0.268    #Intercept
  # beta_TRUE <- 0.0369    #Slope
  N <- n                 #Sample Size
  M <- m                 #Number of experiments/iterations
  
  ## Storage
  intercept_DT <- rep(0, M)
  slope_DT <- rep(0, M)
  train_MSE_DT <- rep(0, M)
  test_MSE_DT <- rep(0, M)
  
  ## begin Monte Carlo
  for (i in 1:M) {
    U_i = rnorm(N, 0, sqrt(abs(dataInput$D47error)))
    x_i = rnorm(N, dataInput$x_TRUE, sqrt(abs(dataInput$TempError)))
    # Y_i = alpha_TRUE + beta_TRUE * x_i + U_i
    Y_i = rnorm(N, dataInput$y_TRUE, sqrt(abs(dataInput$D47error)))
    
    # Formulate data.table
    data_i = data.table(Y = Y_i, X = x_i)
    
    # train test split
    mark <- sample(                       # Mark for train-test
      c(rep(0, 0.7*nrow(data_i)), 
      c(rep(1, 0.3*nrow(data_i)))))      
    train <- data_i[mark == 0,]                # train data
    test <- data_i[mark == 1,]                 # test data
    
    # Run regressions
    ols_i <- lm(data = train, Y ~ X)
    
    # MSE
    train_MSE_DT[i] <- mean((train$Y - predict(ols_i))^2)    # Train set MSE
    test_MSE_DT[i] <- mean((test$Y - predict(ols_i, newdata = test))^2)# Test set MSE
    
    # Extract coefficient and save
    slope_DT[i] <- coef(ols_i)[2]
    intercept_DT[i] <- coef(ols_i)[1]
  }
  
  # Summary statistics
  estimate_DT <- data.table(alpha = intercept_DT, beta = slope_DT, train_MSE = train_MSE_DT, test_MSE = test_MSE_DT)
  
  return(estimate_DT)
}

well_formard <- function(result){
  inteceptCI <- CI(result$alpha)
  slopeCI <- CI(result$beta)
  Intercept_names <- c("Median Intercept", "Intercept Std. Error", "2.5%", "92.5%")
  Intercept_values <- c(summary(result$alpha)[3], sd(result$alpha) / sqrt(length(result$alpha)), inteceptCI[3], inteceptCI[1])
  names(Intercept_values) <- Intercept_names
  
  Slope_names <- c("Median Slope", "Slope Std. Error", "2.5%", "92.5%")
  Slope_values <- c(summary(result$beta)[3], sd(result$beta) / sqrt(length(result$beta)), slopeCI[3], slopeCI[1])
  names(Slope_values) <- Slope_names
    
  MSE_names <- c("Median Train MSE", "Median Test MSE")
  MSE_values <- c(summary(result$train_MSE)[3], summary(result$test_MSE)[3])
  names(MSE_values) <- MSE_names
  
  return (c(Intercept_values, Slope_values, MSE_values))
}

# create data visualization
createPlot <- function(data, result, title, caption) {
  plot_object <- data %>% 
    ggplot(aes(x = x_TRUE, y=y_TRUE)) + 
    geom_ribbon(aes(ymin = result[7] * x_TRUE + result[4] , ymax = result[8] * x_TRUE + result[3]), fill = "orange") +
    geom_point() +
    geom_abline(slope = 0.0369, intercept = 0.268, color = 'red') +
    geom_abline(slope = result[5], intercept = result[1], color = 'yellow') + 
    labs(title = title,
         caption = paste(caption, "\n", greeks("beta"), "=",round(result[1], 4), "(95% CI", round(result[3], 4),"-", round(result[4],4), ")\n"
         , greeks("alpha"), "=",round(result[5], 4), "(95% CI", round(result[7], 4),"-", round(result[8],4), ")" ))+ 
    xlab(expression(paste("True Temperature in ", ""^"o", "K"))) + 
    ylab(expression(paste("True D47 (", ""^"o", "/"["oo"], ")"))) 
  return(plot_object)
}
```

## Low error data
```{r}
result_low <- MonteCarlo(1234, 1000, 1000, data_low)

rbind(well_formard(result_low)) %>% kable()
```

### Comparing result to the true parameters
Plot confident interval area of the median slope/intercept of bootstrapping results
And comparing it to the true slope/intercept

I use the true data points to plot.
```{r}
createPlot(data_low, 
           well_formard(result_low), 
           "LSMC model with the low error data", 
           "LSMC model with the low error data. Red line as true coefficient. Yellow is LSMC fitted coefficient")
```


```{r}
result_intermediate <- MonteCarlo(1234, 1000, 1000, data_intermediate)

rbind(well_formard(result_intermediate)) %>% kable()
```

### Comparing result to the true parameters
Plot confident interval area of the median slope/intercept of bootstrapping results
And comparing it to the true slope/intercept

I use the true data points to plot.
```{r}
createPlot(data_intermediate, 
           well_formard(result_intermediate), 
           "LSMC model with the intermediate error data", 
           "LSMC model with the intermediate error data. Red line as true coefficient. Yellow is LSMC fitted coefficient")
```

```{r}
result_high <- MonteCarlo(1234, 1000, 1000, data_high )

rbind(well_formard(result_high)) %>% kable()
```

### Comparing result to the true parameters
Plot confident interval area of the median slope/intercept of bootstrapping results
And comparing it to the true slope/intercept

I use the true data points to plot.
```{r}
createPlot(data_high, 
           well_formard(result_high), 
           "LSMC model with the high error data", 
           "LSMC model with the high error data. Red line as true coefficient. Yellow is LSMC fitted coefficient")
```
## Median slopes/intercepts VS true parameters

Mean slope/Intercept VS Median slope/Intercept
```{r}
rbind(well_formard(result_low), well_formard(result_intermediate), well_formard(result_high )) %>% kable()
```







